"""
ì „ì„¸ì‚¬ê¸° ìœ„í—˜ë„ ë¶„ì„ API (ë¹„ë™ê¸° + Redis ìºì‹± ë²„ì „)

ë³€ê²½ì‚¬í•­ (v2):
- /predict â†’ ë¹„ë™ê¸° ì²˜ë¦¬ (BackgroundTasks)
  - ìš”ì²­ ì ‘ìˆ˜ â†’ ì¦‰ì‹œ task_id ë°˜í™˜ (202 Accepted)
  - ë°±ê·¸ë¼ìš´ë“œì—ì„œ OCR + ì˜ˆì¸¡ ìˆ˜í–‰
- /predict/{task_id} â†’ ì‘ì—… ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ (í´ë§)
- Redis ìºì‹±: ë™ì¼ ì£¼ì†Œ+ë³´ì¦ê¸ˆ+íŒŒì¼ ì¡°í•© ê²°ê³¼ ì¬ì‚¬ìš©
- /predict/cache â†’ ìºì‹œ ë¬´íš¨í™” API
"""
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Optional
import shutil
import os
import uuid
import asyncio
import logging
from datetime import datetime
from functools import partial
from fastapi.middleware.cors import CORSMiddleware

from app.services.ocr.ledger_parser import extract_building_ledger
from app.services.ocr.registry_parser import extract_real_estate_data
from app.services.predict_service import predict_risk_with_ocr
from app.router import stats
from app.core import (
    get_settings,
    check_db_connection,
    is_db_available,
    reset_db_availability
)
from app.core.exceptions import DatabaseConnectionError, ServiceUnavailableError
from app.services.document_validator import validate_document_match

# Redis ëª¨ë“ˆ
from app.core.redis_config import (
    get_redis,
    close_redis,
    generate_cache_key,
    generate_file_hash,
    get_cached_result,
    set_cached_result,
    invalidate_cache,
    set_task_status,
    get_task_status,
    health_check_redis,
    TaskStatus,
)

logger = logging.getLogger(__name__)

app = FastAPI(
    title="Fraud Detector AI",
    version="2.0",
    description="ì „ì„¸ì‚¬ê¸° ìœ„í—˜ë„ ë¶„ì„ API (ë¹„ë™ê¸° + Redis ìºì‹±)"
)

settings = get_settings()
origins = ["*"] if settings.APP_ENV == "local" else [
    "https://your-frontend-domain.com",
    "https://app.your-domain.com"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE"],
    allow_headers=["*"],
)

# íŒŒì¼ ì—…ë¡œë“œ ì œì•½ì‚¬í•­
MAX_FILE_SIZE_MB = 20
ALLOWED_IMAGE_TYPES = {"image/png", "image/jpeg", "image/jpg"}
ALLOWED_PDF_TYPES = {"application/pdf"}


# =============================================================================
# ì•± Lifecycle (Redis ì—°ê²°/í•´ì œ)
# =============================================================================
@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ Redis ì—°ê²°"""
    redis_client = await get_redis()
    if redis_client:
        logger.info("ğŸš€ Redis ì—°ê²° ì™„ë£Œ")
    else:
        logger.warning("âš ï¸ Redis ì—†ì´ ì‹œì‘ (ìºì‹± ë¹„í™œì„±)")


@app.on_event("shutdown")
async def shutdown_event():
    """ì•± ì¢…ë£Œ ì‹œ Redis ì—°ê²° í•´ì œ"""
    await close_redis()
    logger.info("Redis ì—°ê²° ì¢…ë£Œ")


# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def validate_file_size(file: UploadFile, max_size_mb: int = MAX_FILE_SIZE_MB):
    """íŒŒì¼ í¬ê¸° ê²€ì¦"""
    file.file.seek(0, 2)
    file_size = file.file.tell()
    file.file.seek(0)

    if file_size > max_size_mb * 1024 * 1024:
        raise HTTPException(
            status_code=413,
            detail=f"íŒŒì¼ í¬ê¸°ëŠ” {max_size_mb}MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤ (í˜„ì¬: {file_size / 1024 / 1024:.1f}MB)"
        )


def validate_file_type(file: UploadFile, allowed_types: set):
    """íŒŒì¼ íƒ€ì… ê²€ì¦"""
    if file.content_type not in allowed_types:
        raise HTTPException(
            status_code=415,
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš© í˜•ì‹: {', '.join(allowed_types)}"
        )


def create_error_response(
        status_code: int,
        message: str,
        errors: list,
        suggestions: list = None
) -> JSONResponse:
    """ì—ëŸ¬ ì‘ë‹µ ìƒì„± í—¬í¼ í•¨ìˆ˜"""
    content = {
        "meta": {
            "code": status_code,
            "message": message,
            "timestamp": datetime.now().isoformat()
        },
        "errors": errors
    }
    if suggestions:
        content["suggestions"] = suggestions

    return JSONResponse(status_code=status_code, content=content)


# =============================================================================
# í—¬ìŠ¤ì²´í¬
# =============================================================================
@app.get("/", summary="ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸")
async def health_check():
    redis_status = await health_check_redis()
    return {
        "status": "Healthy",
        "service": "Fraud Detector AI",
        "version": "2.0",
        "redis": redis_status,
    }


# ë¼ìš°í„° ë“±ë¡
app.include_router(stats.router)


# =============================================================================
# ë©”ì¸ ì˜ˆì¸¡ API (ë¹„ë™ê¸° ì „í™˜)
# =============================================================================
@app.post("/predict",
          status_code=202,
          summary="ì „ì„¸ì‚¬ê¸° ìœ„í—˜ë„ ë¶„ì„ ìš”ì²­ (ë¹„ë™ê¸°)",
          description="""
          ê±´ì¶•ë¬¼ëŒ€ì¥(ì´ë¯¸ì§€)ê³¼ ë“±ê¸°ë¶€ë“±ë³¸(PDF)ì„ ì—…ë¡œë“œí•˜ì—¬ ìœ„í—˜ë„ ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤.

          **ë™ì‘ ë°©ì‹:**
          1. ìš”ì²­ ì ‘ìˆ˜ â†’ ì¦‰ì‹œ `task_id` ë°˜í™˜ (202 Accepted)
          2. ë™ì¼ ìš”ì²­ì˜ ìºì‹œê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜ (200 OK)
          3. `/predict/{task_id}` ë¡œ ì§„í–‰ ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ (í´ë§)

          **íŒŒì¼ ì œì•½ì‚¬í•­:**
          - ê±´ì¶•ë¬¼ëŒ€ì¥: PNG, JPG, JPEG (ìµœëŒ€ 10MB, ìµœëŒ€ 5ê°œ)
          - ë“±ê¸°ë¶€ë“±ë³¸: PDF (ìµœëŒ€ 20MB, ìµœëŒ€ 3ê°œ)
          """)
async def predict_risk_endpoint(
        background_tasks: BackgroundTasks,
        deposit: int = Form(..., description="ë³´ì¦ê¸ˆ (ë§Œì›)", ge=0, le=1000000),
        address: str = Form(..., description="ì£¼ì†Œ (ì‹œì„¸ ì¡°íšŒìš©)", min_length=5, max_length=200),
        ledger_files: List[UploadFile] = File(default=None, description="ê±´ì¶•ë¬¼ëŒ€ì¥ ì´ë¯¸ì§€ (PNG/JPG)"),
        registry_files: List[UploadFile] = File(default=None, description="ë“±ê¸°ë¶€ë“±ë³¸ íŒŒì¼ (PDF)"),
        skip_cache: bool = Form(default=False, description="ìºì‹œ ë¬´ì‹œ ì—¬ë¶€ (Trueë©´ ìºì‹œ ê±´ë„ˆëœ€)"),
):
    # === 1. ì…ë ¥ ê²€ì¦ ===
    errors = []

    if not ledger_files or len(ledger_files) == 0:
        errors.append({
            "field": "ledger_files",
            "message": "ê±´ì¶•ë¬¼ëŒ€ì¥ íŒŒì¼ì€ í•„ìˆ˜ì…ë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        })

    if not registry_files or len(registry_files) == 0:
        errors.append({
            "field": "registry_files",
            "message": "ë“±ê¸°ë¶€ë“±ë³¸ íŒŒì¼ì€ í•„ìˆ˜ì…ë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒì˜ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        })

    if ledger_files and len(ledger_files) > 5:
        errors.append({
            "field": "ledger_files",
            "message": "ê±´ì¶•ë¬¼ëŒ€ì¥ì€ ìµœëŒ€ 5ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        })

    if registry_files and len(registry_files) > 3:
        errors.append({
            "field": "registry_files",
            "message": "ë“±ê¸°ë¶€ë“±ë³¸ì€ ìµœëŒ€ 3ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        })

    # íŒŒì¼ íƒ€ì…/í¬ê¸° ê²€ì¦
    if ledger_files:
        for idx, file in enumerate(ledger_files):
            try:
                validate_file_type(file, ALLOWED_IMAGE_TYPES)
                validate_file_size(file, max_size_mb=10)
            except HTTPException as e:
                errors.append({
                    "field": f"ledger_files[{idx}]",
                    "message": f"{file.filename}: {e.detail}"
                })

    if registry_files:
        for idx, file in enumerate(registry_files):
            try:
                validate_file_type(file, ALLOWED_PDF_TYPES)
                validate_file_size(file, max_size_mb=20)
            except HTTPException as e:
                errors.append({
                    "field": f"registry_files[{idx}]",
                    "message": f"{file.filename}: {e.detail}"
                })

    if errors:
        return create_error_response(400, "ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨", errors)

    # === 2. íŒŒì¼ í•´ì‹œ ìƒì„± â†’ ìºì‹œ í‚¤ ===
    file_hashes = []
    file_contents = {}  # {filename: bytes} - ë‚˜ì¤‘ì— ì„ì‹œíŒŒì¼ ì €ì¥ìš©

    for file in (ledger_files or []):
        content = await file.read()
        file_hashes.append(generate_file_hash(content))
        file_contents[f"ledger_{file.filename}"] = content
        await asyncio.to_thread(file.file.seek, 0)

    for file in (registry_files or []):
        content = await file.read()
        file_hashes.append(generate_file_hash(content))
        file_contents[f"registry_{file.filename}"] = content
        await asyncio.to_thread(file.file.seek, 0)

    cache_key = generate_cache_key(address, deposit, file_hashes)

    # === 3. ìºì‹œ í™•ì¸ ===
    if not skip_cache:
        cached_result = await get_cached_result(cache_key)
        if cached_result:
            logger.info(f"ğŸ¯ ìºì‹œ íˆíŠ¸ - ì¦‰ì‹œ ì‘ë‹µ: {cache_key}")
            return JSONResponse(status_code=200, content=cached_result)

    # === 4. ë¹„ë™ê¸° ì‘ì—… ìƒì„± ===
    task_id = str(uuid.uuid4())

    # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
    await set_task_status(task_id, TaskStatus.PENDING, progress=0)

    # ì„ì‹œ íŒŒì¼ ì €ì¥
    temp_dir = f"temp_uploads/{task_id}"
    os.makedirs(temp_dir, exist_ok=True)

    ledger_paths = []
    registry_paths = []

    for file in (ledger_files or []):
        file_path = os.path.join(temp_dir, f"ledger_{datetime.now().timestamp()}_{file.filename}")
        content_key = f"ledger_{file.filename}"
        with open(file_path, "wb") as buffer:
            buffer.write(file_contents[content_key])
        ledger_paths.append(file_path)

    for file in (registry_files or []):
        file_path = os.path.join(temp_dir, f"registry_{datetime.now().timestamp()}_{file.filename}")
        content_key = f"registry_{file.filename}"
        with open(file_path, "wb") as buffer:
            buffer.write(file_contents[content_key])
        registry_paths.append(file_path)

    # === 5. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡ ===
    background_tasks.add_task(
        _run_prediction_task,
        task_id=task_id,
        address=address,
        deposit=deposit,
        ledger_paths=ledger_paths,
        registry_paths=registry_paths,
        cache_key=cache_key,
        temp_dir=temp_dir,
    )

    # === 6. ì¦‰ì‹œ ì‘ë‹µ (202 Accepted) ===
    return JSONResponse(
        status_code=202,
        content={
            "meta": {
                "code": 202,
                "message": "ë¶„ì„ ìš”ì²­ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤",
                "timestamp": datetime.now().isoformat()
            },
            "data": {
                "task_id": task_id,
                "status": TaskStatus.PENDING,
                "cache_key": cache_key,
                "poll_url": f"/predict/{task_id}",
                "estimated_seconds": 15,
            }
        }
    )


# =============================================================================
# ì‘ì—… ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ (í´ë§)
# =============================================================================
@app.get("/predict/{task_id}",
         summary="ë¶„ì„ ì‘ì—… ìƒíƒœ/ê²°ê³¼ ì¡°íšŒ",
         description="""
         `/predict`ì—ì„œ ë°˜í™˜ëœ `task_id`ë¡œ ì§„í–‰ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

         **ìƒíƒœê°’:**
         - `PENDING` â†’ ëŒ€ê¸° ì¤‘
         - `PROCESSING` â†’ ë¶„ì„ ì§„í–‰ ì¤‘ (progress 0~100)
         - `COMPLETED` â†’ ì™„ë£Œ (resultì— ë¶„ì„ ê²°ê³¼ í¬í•¨)
         - `FAILED` â†’ ì‹¤íŒ¨ (errorì— ì‚¬ìœ  í¬í•¨)
         """)
async def get_prediction_status(task_id: str):
    task_data = await get_task_status(task_id)

    if not task_data:
        return create_error_response(
            404,
            "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            [{"field": "task_id", "message": f"'{task_id}' ì‘ì—…ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}],
            suggestions=["ì˜¬ë°”ë¥¸ task_idì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”", "ì‘ì—… ê²°ê³¼ëŠ” 24ì‹œê°„ í›„ ìë™ ì‚­ì œë©ë‹ˆë‹¤"]
        )

    status = task_data.get("status")

    if status == TaskStatus.COMPLETED:
        return JSONResponse(
            status_code=200,
            content={
                "meta": {
                    "code": 200,
                    "message": "ë¶„ì„ ì™„ë£Œ",
                    "timestamp": datetime.now().isoformat()
                },
                "data": {
                    "task_id": task_id,
                    "status": TaskStatus.COMPLETED,
                    "progress": 100,
                    "result": task_data.get("result"),
                }
            }
        )

    elif status == TaskStatus.FAILED:
        return JSONResponse(
            status_code=200,
            content={
                "meta": {
                    "code": 200,
                    "message": "ë¶„ì„ ì‹¤íŒ¨",
                    "timestamp": datetime.now().isoformat()
                },
                "data": {
                    "task_id": task_id,
                    "status": TaskStatus.FAILED,
                    "progress": task_data.get("progress", 0),
                    "error": task_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
                }
            }
        )

    else:
        # PENDING ë˜ëŠ” PROCESSING
        return JSONResponse(
            status_code=200,
            content={
                "meta": {
                    "code": 200,
                    "message": "ë¶„ì„ ì§„í–‰ ì¤‘",
                    "timestamp": datetime.now().isoformat()
                },
                "data": {
                    "task_id": task_id,
                    "status": status,
                    "progress": task_data.get("progress", 0),
                }
            }
        )


# =============================================================================
# ìºì‹œ ê´€ë¦¬ API
# =============================================================================
@app.delete("/predict/cache/{cache_key}",
            summary="íŠ¹ì • ìºì‹œ ë¬´íš¨í™”",
            description="ìºì‹œ í‚¤ë¥¼ ì§€ì •í•˜ì—¬ í•´ë‹¹ ë¶„ì„ ê²°ê³¼ ìºì‹œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
async def delete_cache(cache_key: str):
    success = await invalidate_cache(cache_key)
    if success:
        return {"meta": {"code": 200, "message": "ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}}
    return create_error_response(
        404,
        "ìºì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        [{"field": "cache_key", "message": "í•´ë‹¹ ìºì‹œ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}]
    )


# =============================================================================
# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…: ì‹¤ì œ ì˜ˆì¸¡ ìˆ˜í–‰
# =============================================================================
async def _run_prediction_task(
        task_id: str,
        address: str,
        deposit: int,
        ledger_paths: list,
        registry_paths: list,
        cache_key: str,
        temp_dir: str,
):
    """
    BackgroundTasksì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¹„ë™ê¸° ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸

    ì§„í–‰ ë‹¨ê³„:
    1. DB ì—°ê²° í™•ì¸       (10%)
    2. ê±´ì¶•ë¬¼ëŒ€ì¥ OCR     (30%)
    3. ë“±ê¸°ë¶€ë“±ë³¸ OCR     (50%)
    4. ë¬¸ì„œ ë§¤ì¹­ ê²€ì¦     (60%)
    5. ìœ„í—˜ë„ ì˜ˆì¸¡        (90%)
    6. ê²°ê³¼ ì €ì¥ + ìºì‹±   (100%)
    """
    try:
        # --- Step 1: DB ì—°ê²° í™•ì¸ (10%) ---
        await set_task_status(task_id, TaskStatus.PROCESSING, progress=10)

        if not is_db_available():
            reset_db_availability()
            if not check_db_connection():
                await set_task_status(
                    task_id, TaskStatus.FAILED,
                    error="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )
                return

        ocr_results = {'ledger': {}, 'registry': {}}

        # --- Step 2: ê±´ì¶•ë¬¼ëŒ€ì¥ OCR (30%) ---
        await set_task_status(task_id, TaskStatus.PROCESSING, progress=20)
        logger.info(f"[Task {task_id[:8]}] ê±´ì¶•ë¬¼ëŒ€ì¥ OCR ì‹œì‘...")

        if ledger_paths:
            try:
                # OCRì€ CPU ë°”ìš´ë“œ â†’ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰
                ocr_results['ledger'] = await asyncio.to_thread(
                    extract_building_ledger, ledger_paths
                )
            except Exception as e:
                await set_task_status(
                    task_id, TaskStatus.FAILED, progress=25,
                    error=f"ê±´ì¶•ë¬¼ëŒ€ì¥ OCR ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}. ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                )
                return

        await set_task_status(task_id, TaskStatus.PROCESSING, progress=40)

        # --- Step 3: ë“±ê¸°ë¶€ë“±ë³¸ OCR (50%) ---
        logger.info(f"[Task {task_id[:8]}] ë“±ê¸°ë¶€ë“±ë³¸ OCR ì‹œì‘...")

        if registry_paths:
            try:
                ocr_results['registry'] = await asyncio.to_thread(
                    extract_real_estate_data, registry_paths
                )
            except Exception as e:
                await set_task_status(
                    task_id, TaskStatus.FAILED, progress=45,
                    error=f"ë“±ê¸°ë¶€ë“±ë³¸ OCR ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}. ì„ ëª…í•œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                )
                return

        await set_task_status(task_id, TaskStatus.PROCESSING, progress=60)

        # --- Step 4: ë¬¸ì„œ ë§¤ì¹­ ê²€ì¦ (60%) ---
        logger.info(f"[Task {task_id[:8]}] ë¬¸ì„œ ë§¤ì¹­ ê²€ì¦...")

        ledger_data = ocr_results.get('ledger', {})
        registry_data = ocr_results.get('registry', {})

        if ledger_data and registry_data:
            is_valid, message, details = await asyncio.to_thread(
                validate_document_match, ledger_data, registry_data
            )

            if not is_valid:
                error_result = {
                    "meta": {
                        "code": 422,
                        "message": "ë¬¸ì„œ ë¶ˆì¼ì¹˜ ì˜¤ë¥˜",
                        "timestamp": datetime.now().isoformat()
                    },
                    "errors": [{
                        "field": "documents",
                        "message": message,
                        "details": {
                            "confidence": f"{details['confidence']:.1%}",
                            "issues": details['errors'],
                            "match_scores": {
                                k: f"{v:.1%}"
                                for k, v in details['match_scores'].items()
                            }
                        }
                    }],
                    "suggestions": [
                        "ê±´ì¶•ë¬¼ëŒ€ì¥ê³¼ ë“±ê¸°ë¶€ë“±ë³¸ì´ ê°™ì€ ì£¼ì†Œì˜ ë¬¸ì„œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”",
                        "í˜¸ìˆ˜(ë™/í˜¸)ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”"
                    ]
                }
                await set_task_status(
                    task_id, TaskStatus.FAILED, progress=60,
                    error=message, result=error_result
                )
                return

            if details.get('warnings'):
                logger.warning(f"[ë¬¸ì„œê²€ì¦ ê²½ê³ ] {details['warnings']}")

        await set_task_status(task_id, TaskStatus.PROCESSING, progress=75)

        # --- Step 5: ìœ„í—˜ë„ ì˜ˆì¸¡ (90%) ---
        logger.info(f"[Task {task_id[:8]}] ìœ„í—˜ë„ ì˜ˆì¸¡ ì‹œì‘...")

        result = await asyncio.to_thread(
            predict_risk_with_ocr, address, deposit, ocr_results
        )

        await set_task_status(task_id, TaskStatus.PROCESSING, progress=95)

        # --- Step 6: ê²°ê³¼ ìºì‹± + ì™„ë£Œ (100%) ---
        logger.info(f"[Task {task_id[:8]}] ê²°ê³¼ ìºì‹±...")

        # ì„±ê³µ ê²°ê³¼ë§Œ ìºì‹± (ì—ëŸ¬ ì‘ë‹µì€ ìºì‹±í•˜ì§€ ì•ŠìŒ)
        if "meta" in result and result["meta"].get("code") == 200:
            await set_cached_result(cache_key, result)

        await set_task_status(
            task_id, TaskStatus.COMPLETED,
            progress=100, result=result
        )
        logger.info(f"âœ… [Task {task_id[:8]}] ë¶„ì„ ì™„ë£Œ")

    except DatabaseConnectionError as e:
        logger.error(f"[Task {task_id[:8]}] DB ì—°ê²° ì‹¤íŒ¨: {e}")
        await set_task_status(
            task_id, TaskStatus.FAILED,
            error=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

    except ServiceUnavailableError as e:
        logger.error(f"[Task {task_id[:8]}] ì„œë¹„ìŠ¤ ë¶ˆê°€: {e}")
        await set_task_status(
            task_id, TaskStatus.FAILED,
            error=f"ì„œë¹„ìŠ¤ë¥¼ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        )

    except Exception as e:
        logger.exception(f"[Task {task_id[:8]}] ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
        error_msg = str(e)

        if "Can't connect" in error_msg or "Connection refused" in error_msg:
            error_msg = "Database connection failed"

        await set_task_status(
            task_id, TaskStatus.FAILED,
            error=f"ë¶„ì„ ì‹¤íŒ¨: {error_msg}"
        )

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        _cleanup_temp_files(ledger_paths + registry_paths, temp_dir)


def _cleanup_temp_files(file_paths: list, temp_dir: str):
    """ì„ì‹œ íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì •ë¦¬"""
    for path in file_paths:
        if os.path.exists(path):
            try:
                os.remove(path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {path} - {e}")

    if temp_dir and os.path.exists(temp_dir):
        try:
            shutil.rmtree(temp_dir, ignore_errors=True)
        except Exception as e:
            logger.warning(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {temp_dir} - {e}")


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)